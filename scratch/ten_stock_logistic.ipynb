{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\r\n",
    "sys.path.append('../')\r\n",
    "import libs.db\r\n",
    "import libs.prep_df\r\n",
    "import pandas as pd\r\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = libs.db.get_tickers(\"sp10.csv\")\r\n",
    "num_ticks = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_file = \"sp10_historical.db\"\r\n",
    "conn = libs.db.create_connection(sql_file)\r\n",
    "hist_df = libs.db.df_from_db(conn)\r\n",
    "libs.db.close_connection(conn)\r\n",
    "hist_df = libs.prep_df.normalize_df(hist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "ipykernel_launcher:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17080, 600)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_shifted_df = pd.DataFrame()\r\n",
    "for ticker in tickers:\r\n",
    "    hist_shifted_df[ticker] = hist_df[ticker].copy()\r\n",
    "    for i in range(1,num_ticks):\r\n",
    "        name = f\"{ticker}-{i}\"\r\n",
    "        hist_shifted_df[name] = hist_df[ticker].shift(i)\r\n",
    "hist_shifted_df = hist_shifted_df.copy()\r\n",
    "hist_shifted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_pct_returns_df_list = []\r\n",
    "for ticker in tickers:\r\n",
    "    name = f\"{ticker}_Buy\"\r\n",
    "    returns_df = pd.DataFrame()\r\n",
    "    returns_df[name] = hist_df[ticker].pct_change(periods=16).shift(-16).apply(lambda x : 1 if x >= 0.0075 else 0)\r\n",
    "    hist_pct_returns_df_list.append(returns_df)\r\n",
    "len(hist_pct_returns_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_file = \"sp10_current.db\"\r\n",
    "conn = libs.db.create_connection(sql_file)\r\n",
    "current_df = libs.db.df_from_db(conn)\r\n",
    "libs.db.close_connection(conn)\r\n",
    "current_df = libs.prep_df.normalize_df(current_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "ipykernel_launcher:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    }
   ],
   "source": [
    "current_shifted_df = pd.DataFrame()\r\n",
    "for ticker in tickers:\r\n",
    "    current_shifted_df[ticker] = current_df[ticker].copy()\r\n",
    "    for i in range(1,num_ticks):\r\n",
    "        name = f\"{ticker}-{i}\"\r\n",
    "        current_shifted_df[name] = current_df[ticker].shift(i)\r\n",
    "current_shifted_df = current_shifted_df.copy()\r\n",
    "current_shifted_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17020, 610)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_pctchange_df = hist_shifted_df.pct_change()\r\n",
    "hist_pctchange_df = pd.concat([hist_pctchange_df, *hist_pct_returns_df_list], axis=1)\r\n",
    "hist_pctchange_df.dropna(inplace=True)\r\n",
    "hist_pctchange_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_pctchange_df = current_shifted_df.pct_change()\r\n",
    "current_pctchange_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_start = len(tickers)*num_ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hist_pctchange_df.iloc[:,0:y_start].values\r\n",
    "y = []\r\n",
    "for i in range(0,len(tickers)):\r\n",
    "    y.append(hist_pctchange_df.iloc[:,y_start+i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "AAPL\n",
      "Training Data Score: 0.6832745789267528\n",
      "Testing Data Score: 0.6808460634547591\n",
      "[[2897    2]\n",
      " [1356    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Buy       0.68      1.00      0.81      2899\n",
      "         Buy       0.00      0.00      0.00      1356\n",
      "\n",
      "    accuracy                           0.68      4255\n",
      "   macro avg       0.34      0.50      0.41      4255\n",
      "weighted avg       0.46      0.68      0.55      4255\n",
      "\n",
      "--------------------------------------\n",
      "MSFT\n",
      "Training Data Score: 0.7029377203290247\n",
      "Testing Data Score: 0.7008225616921269\n",
      "[[2981    0]\n",
      " [1273    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Buy       0.70      1.00      0.82      2981\n",
      "         Buy       1.00      0.00      0.00      1274\n",
      "\n",
      "    accuracy                           0.70      4255\n",
      "   macro avg       0.85      0.50      0.41      4255\n",
      "weighted avg       0.79      0.70      0.58      4255\n",
      "\n",
      "--------------------------------------\n",
      "AMZN\n",
      "Training Data Score: 0.673090481786134\n",
      "Testing Data Score: 0.6698002350176263\n",
      "[[2849    2]\n",
      " [1403    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Buy       0.67      1.00      0.80      2851\n",
      "         Buy       0.33      0.00      0.00      1404\n",
      "\n",
      "    accuracy                           0.67      4255\n",
      "   macro avg       0.50      0.50      0.40      4255\n",
      "weighted avg       0.56      0.67      0.54      4255\n",
      "\n",
      "--------------------------------------\n",
      "FB\n",
      "Training Data Score: 0.6778691735213475\n",
      "Testing Data Score: 0.6745005875440658\n",
      "[[2870    1]\n",
      " [1384    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Buy       0.67      1.00      0.81      2871\n",
      "         Buy       0.00      0.00      0.00      1384\n",
      "\n",
      "    accuracy                           0.67      4255\n",
      "   macro avg       0.34      0.50      0.40      4255\n",
      "weighted avg       0.46      0.67      0.54      4255\n",
      "\n",
      "--------------------------------------\n",
      "GOOGL\n",
      "Training Data Score: 0.7045045045045045\n",
      "Testing Data Score: 0.7024676850763807\n",
      "[[2986    0]\n",
      " [1266    3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Buy       0.70      1.00      0.83      2986\n",
      "         Buy       1.00      0.00      0.00      1269\n",
      "\n",
      "    accuracy                           0.70      4255\n",
      "   macro avg       0.85      0.50      0.41      4255\n",
      "weighted avg       0.79      0.70      0.58      4255\n",
      "\n",
      "--------------------------------------\n",
      "TSLA\n",
      "Training Data Score: 0.5893458676067371\n",
      "Testing Data Score: 0.5866039952996475\n",
      "[[2495    6]\n",
      " [1753    1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Buy       0.59      1.00      0.74      2501\n",
      "         Buy       0.14      0.00      0.00      1754\n",
      "\n",
      "    accuracy                           0.59      4255\n",
      "   macro avg       0.37      0.50      0.37      4255\n",
      "weighted avg       0.40      0.59      0.44      4255\n",
      "\n",
      "--------------------------------------\n",
      "BRK.B\n",
      "Training Data Score: 0.7681942812377595\n",
      "Testing Data Score: 0.7675675675675676\n",
      "[[3266    2]\n",
      " [ 987    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Buy       0.77      1.00      0.87      3268\n",
      "         Buy       0.00      0.00      0.00       987\n",
      "\n",
      "    accuracy                           0.77      4255\n",
      "   macro avg       0.38      0.50      0.43      4255\n",
      "weighted avg       0.59      0.77      0.67      4255\n",
      "\n",
      "--------------------------------------\n",
      "NVDA\n",
      "Training Data Score: 0.5971797884841363\n",
      "Testing Data Score: 0.5924794359576968\n",
      "[[2513    5]\n",
      " [1729    8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Buy       0.59      1.00      0.74      2518\n",
      "         Buy       0.62      0.00      0.01      1737\n",
      "\n",
      "    accuracy                           0.59      4255\n",
      "   macro avg       0.60      0.50      0.38      4255\n",
      "weighted avg       0.60      0.59      0.44      4255\n",
      "\n",
      "--------------------------------------\n",
      "JPM\n",
      "Training Data Score: 0.718213866039953\n",
      "Testing Data Score: 0.7172737955346651\n",
      "[[3052    3]\n",
      " [1200    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Buy       0.72      1.00      0.84      3055\n",
      "         Buy       0.00      0.00      0.00      1200\n",
      "\n",
      "    accuracy                           0.72      4255\n",
      "   macro avg       0.36      0.50      0.42      4255\n",
      "weighted avg       0.52      0.72      0.60      4255\n",
      "\n",
      "--------------------------------------\n",
      "JNJ\n",
      "Training Data Score: 0.7784567175871524\n",
      "Testing Data Score: 0.7776733254994125\n",
      "[[3309    3]\n",
      " [ 943    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Buy       0.78      1.00      0.87      3312\n",
      "         Buy       0.00      0.00      0.00       943\n",
      "\n",
      "    accuracy                           0.78      4255\n",
      "   macro avg       0.39      0.50      0.44      4255\n",
      "weighted avg       0.61      0.78      0.68      4255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_models = []\r\n",
    "log_confusion = []\r\n",
    "log_classification = []\r\n",
    "target_names = [\"Not Buy\", \"Buy\"]\r\n",
    "for i in range(0,len(tickers)):\r\n",
    "    ticker = tickers[i]\r\n",
    "    model = LogisticRegression(solver='lbfgs')\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y[i],random_state=1,stratify=y[i])\r\n",
    "    model.fit(X_train,y_train)\r\n",
    "    log_models.append(model)\r\n",
    "    predicted = model.predict(X_test)\r\n",
    "    log_confusion.append(confusion_matrix(y_test, predicted))\r\n",
    "    log_classification.append(classification_report(y_test, predicted, target_names=target_names))\r\n",
    "    print(\"--------------------------------------\")\r\n",
    "    print(ticker)\r\n",
    "    print(f\"Training Data Score: {model.score(X_train, y_train)}\")\r\n",
    "    print(f\"Testing Data Score: {model.score(X_test, y_test)}\")\r\n",
    "    print(log_confusion[i])\r\n",
    "    print(log_classification[i])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL 0\n",
      "MSFT 0\n",
      "AMZN 0\n",
      "FB 0\n",
      "GOOGL 0\n",
      "TSLA 0\n",
      "BRK.B 0\n",
      "NVDA 0\n",
      "JPM 0\n",
      "JNJ 0\n"
     ]
    }
   ],
   "source": [
    "#Predict pct-change for each of the tickers over the month of June 2021\r\n",
    "y_current_predicted = []\r\n",
    "current_returns_df_list = []\r\n",
    "X = current_pctchange_df.values\r\n",
    "for i in range(0,len(tickers)):\r\n",
    "    ticker = tickers[i]\r\n",
    "    model = log_models[i]\r\n",
    "    predicted = model.predict(X)\r\n",
    "    y_current_predicted.append(predicted)\r\n",
    "    return_df = pd.DataFrame({\"timestamp\":current_pctchange_df.index, \"buy_predicted\": predicted})\r\n",
    "    return_df = return_df.set_index(\"timestamp\")\r\n",
    "    return_df = return_df.merge(current_df[ticker], how=\"left\", on=\"timestamp\")\r\n",
    "    print(ticker, return_df[\"buy_predicted\"].sum())\r\n",
    "\r\n",
    "    money = 10000\r\n",
    "    num_shares = 0\r\n",
    "    state = 0\r\n",
    "    buy_index = 0\r\n",
    "    money_list=[]\r\n",
    "\r\n",
    "    for i in range(0,len(return_df)):\r\n",
    "        if state == 1 and i == buy_index + 16:\r\n",
    "            #sell\r\n",
    "            price = return_df.iloc[i,1]\r\n",
    "            money = num_shares * price\r\n",
    "            state = 0\r\n",
    "            print(f\"sell {ticker}\", i ,price)\r\n",
    "\r\n",
    "        if return_df.iloc[i,0] == 1 and state == 0 and i < len(return_df) - 16:\r\n",
    "            #buy\r\n",
    "            price = return_df.iloc[i,1]\r\n",
    "            num_shares = money / price\r\n",
    "            buy_index = i\r\n",
    "            state = 1\r\n",
    "            print(f\"buy {ticker}\", i, price)\r\n",
    "\r\n",
    "        if return_df.iloc[i,0] == 1 and state == 1 and i < len(return_df) - 16:\r\n",
    "            buy_index = i\r\n",
    "\r\n",
    "        if state == 0 :\r\n",
    "            money_list.append(money)\r\n",
    "        else:\r\n",
    "            price = return_df.iloc[i,1]\r\n",
    "            money_list.append(num_shares*price)\r\n",
    "    \r\n",
    "    return_df[\"ROI\"] = money_list\r\n",
    "\r\n",
    "    current_returns_df_list.append(return_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "625649fb277a33020e30d480432fe83a3c34bdae155bdecae638a11130d5bfb4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}